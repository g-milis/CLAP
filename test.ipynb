{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ylTnms6XcgYo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\George\\miniconda3\\envs\\patrec\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REQUEST: <PreparedRequest [HEAD]>\n",
            "REQUEST: <PreparedRequest [HEAD]>\n",
            "REQUEST: <PreparedRequest [HEAD]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\George\\miniconda3\\envs\\patrec\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REQUEST: <PreparedRequest [HEAD]>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing CustomRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing CustomRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing CustomRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of CustomRobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.encoder.log_reweighting', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REQUEST: <PreparedRequest [HEAD]>\n",
            "Load our best checkpoint in the paper.\n",
            "The checkpoint is already downloaded\n",
            "Load Checkpoint...\n",
            "Activating gradients for text_branch.encoder.log_reweighting\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "from src import laion_clap\n",
        "\n",
        "# quantization\n",
        "def int16_to_float32(x):\n",
        "    return (x / 32767.0).astype(np.float32)\n",
        "\n",
        "\n",
        "def float32_to_int16(x):\n",
        "    x = np.clip(x, a_min=-1., a_max=1.)\n",
        "    return (x * 32767.).astype(np.int16)\n",
        "\n",
        "model = laion_clap.CLAP_Module(enable_fusion=False, tmodel='roberta')\n",
        "model.load_ckpt() # download the default pretrained checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "kE5tW2EHc9oa",
        "outputId": "34e175c4-a0fa-4a37-ce9c-07a7c13c7c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0')\n",
            "tensor([[-0.0092,  0.0250,  0.0036,  ...,  0.0106, -0.0013, -0.0652],\n",
            "        [-0.0201,  0.0314,  0.0824,  ..., -0.0968,  0.0011, -0.0711]],\n",
            "       device='cuda:0', grad_fn=<DivBackward0>)\n",
            "torch.Size([2, 512])\n"
          ]
        }
      ],
      "source": [
        "# # Directly get audio embeddings from audio files\n",
        "# audio_file = [\n",
        "#     'assets/audio_original.wav'\n",
        "# ]\n",
        "# audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=False)\n",
        "# print(audio_embed[:,-20:])\n",
        "# print(audio_embed.shape)\n",
        "\n",
        "# # Get audio embeddings from audio data\n",
        "# audio_data, _ = librosa.load(audio_file[0], sr=48000) # sample rate should be 48000\n",
        "# audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
        "# audio_embed = model.get_audio_embedding_from_data(x = audio_data, use_tensor=False)\n",
        "# print(audio_embed[:,-20:])\n",
        "# print(audio_embed.shape)\n",
        "\n",
        "# # Directly get audio embeddings from audio files, but return torch tensor\n",
        "# audio_embed = model.get_audio_embedding_from_filelist(x = audio_file, use_tensor=True)\n",
        "# print(audio_embed[:,-20:])\n",
        "# print(audio_embed.shape)\n",
        "\n",
        "# # Get audio embeddings from audio data\n",
        "# audio_data, _ = librosa.load(audio_file[0], sr=48000) # sample rate should be 48000\n",
        "# audio_data = audio_data.reshape(1, -1) # Make it (1,T) or (N,T)\n",
        "# audio_data = torch.from_numpy(int16_to_float32(float32_to_int16(audio_data))).float() # quantize before send it in to the model\n",
        "# audio_embed = model.get_audio_embedding_from_data(x = audio_data, use_tensor=True)\n",
        "# print(audio_embed[:,-20:])\n",
        "# print(audio_embed.shape)\n",
        "\n",
        "# Get text embedings from texts\n",
        "text_data = [\"I love the contrastive learning\", \"I love the pretrain model\"]\n",
        "text_embed = model.get_text_embedding(text_data, use_tensor=True)\n",
        "print(text_embed)\n",
        "print(text_embed.shape)\n",
        "\n",
        "# torch.save(text_embed, \"roberta_test.pt\")\n",
        "\n",
        "# Are the embeddings the same as RoBERTa?\n",
        "assert torch.all(text_embed == torch.load(\"roberta_test.pt\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
