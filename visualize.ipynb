{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing empty model here (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing CustomRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CustomRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomRobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.log_reweighting', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the specified checkpoint /fs/nexus-scratch/milis/848K/CLAP/logs/reweighting_5/checkpoints/epoch_latest.pt from users.\n",
      "Load Checkpoint...\n",
      "Loaded state dict to memory (1)\n",
      "Reweighting modules:\n",
      "['text_branch.log_reweighting']\n",
      "Loading state dict to model (2)\n",
      "Loaded state dict to model strictly (3)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "from src import laion_clap\n",
    "\n",
    "\n",
    "checkpoint_path = \"/fs/nexus-scratch/milis/848K/CLAP/logs/reweighting_5/checkpoints/epoch_latest.pt\"\n",
    "\n",
    "\n",
    "model = laion_clap.CLAP_Module()\n",
    "model.load_ckpt(checkpoint_path)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "log_reweighting = model.model.text_branch.log_reweighting\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    token_ids = tokenizer.encode(text)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    return token_ids, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def visualize_sentences(tokenized_sentences, token_weights):\n",
    "    # Get colormap\n",
    "    cmap = matplotlib.cm.get_cmap(\"OrRd\")\n",
    "    \n",
    "    # Build HTML for each sentence\n",
    "    sentence_html_list = []\n",
    "    for tokens, weights in zip(tokenized_sentences, token_weights):\n",
    "        # Normalize weights to [0, 1]\n",
    "        weights = np.array(weights)\n",
    "        norm_weights = (weights - min(weights)) / (max(weights) - min(weights))\n",
    "        \n",
    "        # Convert weights to colors\n",
    "        colors = [matplotlib.colors.rgb2hex(cmap(w)) for w in norm_weights]\n",
    "\n",
    "        print(\"Tokens:\", tokens)\n",
    "        print(\"Weights:\", [round(w, 2) for w in weights])\n",
    "        \n",
    "        # Reconstruct the original sentence with token highlights\n",
    "        highlighted_sentence = \"\"\n",
    "        for i, token in enumerate(tokens):\n",
    "            # Remove prefix indicators (e.g., ## or Ġ) for natural appearance\n",
    "            if \"##\" in token or \"Ġ\" in token:\n",
    "                token = \" \" + token.replace(\"Ġ\", \"\")\n",
    "            if token in [\"<s>\", \"</s>\"]:\n",
    "                token = \"\"\n",
    "            color = colors[i]\n",
    "            highlighted_sentence += f'<span style=\"background-color:{color}; color:black; padding:0px; border-radius:3px; font-weight:bold;\">{token}</span>'\n",
    "        \n",
    "        # Append the highlighted sentence to the list\n",
    "        sentence_html_list.append(f\"<li>{highlighted_sentence.strip()}</li>\")\n",
    "    \n",
    "    # Combine all sentences into a single container with a white background\n",
    "    html_content = f\"\"\"\n",
    "    <div style='font-family:monospace; background-color:white; padding:10px;'>\n",
    "        <ul style='list-style-type:none; padding:1px; margin:1px;'>\n",
    "            {''.join(sentence_html_list)}\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html_content))\n",
    "\n",
    "\n",
    "def visualize_data_driven(sentences):\n",
    "    \"\"\"\n",
    "    sentences: list of strings\n",
    "    \"\"\"\n",
    "    tokenized_sentences_list = []\n",
    "    tokenized_weights_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        token_ids, tokens = tokenize(sentence)\n",
    "        tokenized_sentences_list.append(tokens)\n",
    "\n",
    "        log_weights = log_reweighting[token_ids]\n",
    "        weights = torch.exp(log_weights).squeeze().tolist()\n",
    "        tokenized_weights_list.append(weights)\n",
    "\n",
    "    visualize_sentences(tokenized_sentences_list, tokenized_weights_list)\n",
    "\n",
    "\n",
    "def visualize_user_driven(sentences, weights_list, sos_token=\"<s>\", eos_token=\"</s>\", default_weight=1.0):\n",
    "    \"\"\"\n",
    "    sentences: list of strings\n",
    "    weights: list of lists of floats\n",
    "    \"\"\"\n",
    "    tokenized_sentences_list = []\n",
    "    tokenized_weights_list = []\n",
    "\n",
    "    for sentence, weights in zip(sentences, weights_list):\n",
    "        words = sentence.split()\n",
    "        # Initialize tokenized sentence and weights\n",
    "        tokenized_sentence = []\n",
    "        tokenized_weights = []\n",
    "\n",
    "        # Add <SOS> token and its weight\n",
    "        tokenized_sentence.append(sos_token)\n",
    "        tokenized_weights.append(default_weight)\n",
    "\n",
    "        # Process each word and its weight\n",
    "        i = 0\n",
    "        for word, weight in zip(words, weights):\n",
    "            if i != 0:\n",
    "                word = \" \" + word\n",
    "            i += 1\n",
    "            # Tokenize the word into subwords\n",
    "            subwords = tokenize(word)[1][1:-1]\n",
    "\n",
    "            # Extend tokenized sentence and replicate the weight for each subword\n",
    "            tokenized_sentence.extend(subwords)\n",
    "            tokenized_weights.extend([weight] * len(subwords))\n",
    "\n",
    "        # Add <EOS> token and its weight\n",
    "        tokenized_sentence.append(eos_token)\n",
    "        tokenized_weights.append(default_weight)\n",
    "\n",
    "        tokenized_sentences_list.append(tokenized_sentence)\n",
    "        tokenized_weights_list.append(tokenized_weights)\n",
    "\n",
    "    visualize_sentences(tokenized_sentences_list, tokenized_weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['<s>', 'The', 'Ġsound', 'Ġof', 'Ġthe', 'Ġocean', 'Ġwaves', 'Ġcrashing', 'Ġwhile', 'Ġa', 'Ġkid', 'Ġis', 'Ġyelling', '.', '</s>']\n",
      "Weights: [0.89, 0.9, 0.83, 0.97, 0.88, 1.09, 1.14, 1.08, 0.94, 0.99, 0.77, 1.14, 1.12, 0.82, 1.36]\n",
      "Tokens: ['<s>', 'You', 'Ġcan', 'Ġhear', 'Ġa', 'Ġlot', 'Ġof', 'Ġcar', 'Ġnoises', 'Ġin', 'Ġthe', 'Ġbackground', '.', '</s>']\n",
      "Weights: [0.89, 1.0, 0.97, 0.94, 0.99, 0.94, 0.97, 0.98, 1.01, 0.87, 0.88, 0.94, 0.82, 1.36]\n",
      "Tokens: ['<s>', 'A', 'Ġperson', 'Ġis', 'Ġrunning', 'Ġand', 'Ġyou', 'Ġcan', 'Ġhear', 'Ġtheir', 'Ġfoot', 'run', '.', '</s>']\n",
      "Weights: [0.89, 0.97, 1.02, 1.14, 0.99, 0.84, 0.97, 0.97, 0.94, 0.88, 0.93, 1.0, 0.82, 1.36]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='font-family:monospace; background-color:white; padding:10px;'>\n",
       "        <ul style='list-style-type:none; padding:1px; margin:1px;'>\n",
       "            <li><span style=\"background-color:#fddbac; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span><span style=\"background-color:#fdd9a8; color:black; padding:0px; border-radius:3px; font-weight:bold;\">The</span><span style=\"background-color:#feebd0; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> sound</span><span style=\"background-color:#fdc18a; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> of</span><span style=\"background-color:#fddeb3; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> the</span><span style=\"background-color:#f77f53; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> ocean</span><span style=\"background-color:#ed6145; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> waves</span><span style=\"background-color:#f98254; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> crashing</span><span style=\"background-color:#fdcd96; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> while</span><span style=\"background-color:#fdba83; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> a</span><span style=\"background-color:#fff7ec; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> kid</span><span style=\"background-color:#f06749; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> is</span><span style=\"background-color:#f26e4c; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> yelling</span><span style=\"background-color:#feeed5; color:black; padding:0px; border-radius:3px; font-weight:bold;\">.</span><span style=\"background-color:#7f0000; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span></li><li><span style=\"background-color:#fee6c4; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span><span style=\"background-color:#fdc38d; color:black; padding:0px; border-radius:3px; font-weight:bold;\">You</span><span style=\"background-color:#fdcd96; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> can</span><span style=\"background-color:#fdd9aa; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> hear</span><span style=\"background-color:#fdc68f; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> a</span><span style=\"background-color:#fdd9a8; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> lot</span><span style=\"background-color:#fdcd96; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> of</span><span style=\"background-color:#fdcc96; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> car</span><span style=\"background-color:#fdc089; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> noises</span><span style=\"background-color:#feecd1; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> in</span><span style=\"background-color:#fee9ca; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> the</span><span style=\"background-color:#fdd9a8; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> background</span><span style=\"background-color:#fff7ec; color:black; padding:0px; border-radius:3px; font-weight:bold;\">.</span><span style=\"background-color:#7f0000; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span></li><li><span style=\"background-color:#fee6c4; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span><span style=\"background-color:#fdd09a; color:black; padding:0px; border-radius:3px; font-weight:bold;\">A</span><span style=\"background-color:#fdbd86; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> person</span><span style=\"background-color:#f3714d; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> is</span><span style=\"background-color:#fdc690; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> running</span><span style=\"background-color:#fff3e3; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> and</span><span style=\"background-color:#fdce98; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> you</span><span style=\"background-color:#fdcd96; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> can</span><span style=\"background-color:#fdd9aa; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> hear</span><span style=\"background-color:#fee9ca; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> their</span><span style=\"background-color:#fddcaf; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> foot</span><span style=\"background-color:#fdc38d; color:black; padding:0px; border-radius:3px; font-weight:bold;\">run</span><span style=\"background-color:#fff7ec; color:black; padding:0px; border-radius:3px; font-weight:bold;\">.</span><span style=\"background-color:#7f0000; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span></li>\n",
       "        </ul>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['<s>', 'This', 'Ġis', 'Ġa', 'Ġtest', 'tt', 't', '</s>']\n",
      "Weights: [1.0, 0.1, 0.2, 0.8, 0.3, 0.3, 0.3, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style='font-family:monospace; background-color:white; padding:10px;'>\n",
       "        <ul style='list-style-type:none; padding:1px; margin:1px;'>\n",
       "            <li><span style=\"background-color:#7f0000; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span><span style=\"background-color:#fff7ec; color:black; padding:0px; border-radius:3px; font-weight:bold;\">This</span><span style=\"background-color:#feeacc; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> is</span><span style=\"background-color:#ce2417; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> a</span><span style=\"background-color:#fdd9a8; color:black; padding:0px; border-radius:3px; font-weight:bold;\"> test</span><span style=\"background-color:#fdd9a8; color:black; padding:0px; border-radius:3px; font-weight:bold;\">tt</span><span style=\"background-color:#fdd9a8; color:black; padding:0px; border-radius:3px; font-weight:bold;\">t</span><span style=\"background-color:#7f0000; color:black; padding:0px; border-radius:3px; font-weight:bold;\"></span></li>\n",
       "        </ul>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The sound of the ocean waves crashing while a kid is yelling.\",\n",
    "    \"You can hear a lot of car noises in the background.\",\n",
    "    \"A person is running and you can hear their footrun.\"\n",
    "]\n",
    "\n",
    "visualize_data_driven(sentences)\n",
    "\n",
    "\n",
    "sentences = [\"This is a testttt\"]\n",
    "weights = [[0.1, 0.2, 0.8, 0.3]]\n",
    "\n",
    "visualize_user_driven(sentences, weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
